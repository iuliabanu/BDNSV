# AI for Relational databases 

## Introduction 

Natural language interface to the database allows non-skilled users to access structured databases and mitigates hallucination by integrating relevant content from databases. 

**Text-to-sql**: convert NL questions into SQL queries. 

**INPUT**: NL question, database schema. 

**OUTPUT**: query or query execution result. 

Converting a NL question into a SQL-query requires resolving the language ambiguities and understanding the exact semantic of user's input. Accurate SQL queries are generated based on a comprehensive knowledge of the database schema: table names, column names, constraints, and relationships. 

Text-to-SQL systems evolved from rule-based methods, deep-learning approaches using LSTM, transforms, GNN, to pretrained based implementations using BERT or RoBERTa  and  advanced LLM based implementations. All types of systems face challenges like interpreting difficult and rare operations such as nested clauses or outer joins; working with new untrained domains when database schema or vocabulary differ from training data.  

## Methods 

### In context learning or prompt engineering:  

**One-shot**: The prompt includes the user's query and database schema content such as table and column names, primary or foreign keys indicating the relationships between entities.    

**Few-shot**: The prompt includes the user's query, database schema content, and a fixed number of question-query pairs. 

Hallucinations can be often reduced by using few-shot prompts that include sample records for the target tables or DDL commands, but alterations in schema presentation or choice of few shots may result in different LLM outputs.   

### Decomposition 

Databases often have complex schemas, and a user's question might imply multiple tables. Because of the requested high precision, complex queries, for example those using nested subqueries, aggregate functions, or window operations, are typically too difficult for today's LLMs to handle. The method of decomposition reduces text-to-sql tasks to simpler subtasks and eliminates irrelevant information in each step.  

In [2], a workflow paradigm is proposed to boost the attention of LLMs for complex problems. The workflow comprises five steps: 

- Information determination: identify tables and columns that the problem needs to use, this step prevents errors like selecting an excessive number of fields or selecting incorrect fields, inconsistencies between the tables and fields used, etc. 

- Classification & Hint: distinguish between nesting and joining and add hints based on the query type; LLMs may predict incorrect join types (left instead of inner join) or incorrect join conditions. 

- SQL generation: generate the query based on the first two steps; 

- Self-correction: set up relevant error prompts specifically targeting issues in step 3. 

- Active learning: expand the solvable problem domain by prompting questions with the SQL generated by the LLM and modified SQL, correcting the initial response. 

In [3] the SQL generation process comprises three steps mitigating the LLM’s sensitivity to prompts and ensuring the generation of more robust answers:  

- Schema linking: select tables and columns relevant to the question from the DB schema using multiple prompts, ask the LLM why each table or column is necessary; 

- Multiple SQL generation: employ various prompts to produce diverse candidate SQL queries, ensuring a broader exploration of potential queries by varying both the selection method of the few-shot examples and the order in which they are presented; 

- Selection: filter candidate queries based on confidence scores, the optimal query is selected through multiple-choice selection (MCS) that is presented to the LLM. The confidence score is determined based on the number of queries that produce the same execution result, Among the queries in candidate pool C with identical execution results, only the query with the minimum execution time is selected. 

In [4] Least-to-Most prompting is used to break complex questions into step-by-step sub-questions to facilitate SQL generation. 

### Reasoning Enhancement 

Helping the LLM explicitly structure the complex steps required to map a natural language question to a complex SQL query is achieved by incorporating advanced reasoning techniques like Chain-of-Thought (CoT) Prompting. e.g., "First, find the event ID. Second, count the students attending the event." 

### Execution Refinement 

To ensure its correctness and accuracy of the results, execution refinement involves using external feedback, interacting with the target database itself after an SQL query has been generated. This iterative process works as follows: 

Execution and Error Detection: The LLM generates an SQL query, which is then sent to the actual database for execution. 

Feedback Loop: If the query fails to execute (a syntax error) or executes but returns an incorrect result (a semantic error), the error message or the unexpected result is fed back to the LLM. 

Self-Correction: The LLM, acting as a Refiner, uses this database feedback and the original prompt context to reason why the query failed and then generates a revised (refined) SQL query. 

## Benchmarks 

### Spider 

Spider 2.0 is an evaluation framework comprising 632 real-world text-to-SQL workflow problems derived from enterprise-level database use cases. The databases in Spider 2.0 are sourced from real data applications, often containing over 1,000 columns and stored in local or cloud database systems such as BigQuery and Snowflake. This challenge calls for models to interact with complex SQL workflow environments, process extremely long contexts, perform intricate reasoning, and generate multiple SQL queries with diverse operations, often exceeding 100 lines, which goes far beyond traditional text-to-SQL challenges. [4] 

### Bird  

BIRD (BIg Bench for LaRge-scale Database Grounded Text-to-SQL Evaluation) represents a pioneering, cross-domain dataset that examines the impact of extensive database contents on text-to-SQL parsing. BIRD contains over 12,751 unique question-SQL pairs, 95 big databases with a total size of 33.4 GB. It also covers more than 37 professional domains, such as blockchain, hockey, healthcare and education, etc. [5] 

## Implementations in LangChain 

### Chains 

Chains encode a fixed predetermined sequence of steps. Each step has a well-defined role. The flow of a chain is linear and deterministic. A step may be a call to components like models, document retrievers, other Chains, etc.[6] 

### Agents 

An agent is more dynamic and flexible. It uses an LLM as a "reasoning engine" to decide which steps to take next. An agent is non-deterministic and can handle unexpected situations. [7] 


## References 

[1] HONG, Zijin, et al. [Next-generation database interfaces: A survey of llm-based text-to-sql](https://arxiv.org/pdf/2406.08426? ). arXiv preprint arXiv:2406.08426, 2024.  



[2] XIE, Yuanzhen, et al. [Decomposition for enhancing attention: Improving llm-based Text-to-SQL through workflow paradigm.](https://arxiv.org/pdf/2402.10671 ) arXiv preprint arXiv:2402.10671, 2024. 


[3] LEE, Dongjun, et al. [Mcs-sql: Leveraging multiple prompts and multiple-choice selection for text-to-sql generation](https://arxiv.org/pdf/2405.07467). arXiv preprint arXiv:2405.07467, 2024.
 

[4] [Spider](https://spider2-sql.github.io/) benchmark

[5] [Bird](https://bird-bench.github.io/) benchmark  

[Bird Data set](https://github.com/ContextualAI/bird-sql/blob/main/src/prep_data.py) 

[6] [LangChain – chains](https://python.langchain.com/api_reference/langchain/chains.html) docs

[7] [LangChain - agents](https://python.langchain.com/docs/tutorials/agents/) docs

[8] [Build a Question/Answering system over SQL data](https://python.langchain.com/docs/tutorials/sql_qa/) 

[9] [Advanced RAG techniques with LangChain](https://medium.com/@roberto.g.infante/advanced-rag-techniques-with-langchain-part-8-5c0832da2329) 

[10] MOHAMMADJAFARI, Ali; MAIDA, Anthony S.; GOTTUMUKKALA, Raju. [From natural language to sql: Review of llm-based text-to-sql systems.](https://arxiv.org/pdf/2410.01066 ) arXiv preprint arXiv:2410.01066, 2024. 

[11] ZHANG, Qinggang, et al. [Structure guided large language model for sql generation.](https://arxiv.org/pdf/2402.13284) arXiv preprint arXiv:2402.13284, 2024. 

